{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aed7b60",
   "metadata": {},
   "source": [
    "inspired by:\n",
    "\n",
    "https://www.kaggle.com/code/robikscube/sentiment-analysis-python-youtube-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a65e3a1",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea3ebd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import textwrap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4708246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/juliuseg/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/juliuseg/nltk_data', '/Users/juliuseg/DTU/CompTools/.venv/nltk_data', '/Users/juliuseg/DTU/CompTools/.venv/share/nltk_data', '/Users/juliuseg/DTU/CompTools/.venv/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/juliuseg/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/juliuseg/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Force re-download the punkt resource\n",
    "nltk.download('punkt', force=True)\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Check all available resources and their locations\n",
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4a8a24",
   "metadata": {},
   "source": [
    "# Random hotel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ac234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429465, 6)\n",
      "(5000, 6)\n"
     ]
    }
   ],
   "source": [
    "# Read in data\n",
    "df_full = pd.read_csv('data/reviews_airbnb.csv') # https://www.kaggle.com/datasets/nikitaryabukhin/reviewshotel?select=reviews_hotel1.csv\n",
    "print(df_full.shape)\n",
    "# Drop nan reviews\n",
    "# df_full = df_full[df_full['reviews.text'].notna()]\n",
    "df = df_full.head(5000)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e576ee90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1312191</td>\n",
       "      <td>6662965</td>\n",
       "      <td>2013-08-20</td>\n",
       "      <td>7403659</td>\n",
       "      <td>Anne</td>\n",
       "      <td>Nous sommes des français qui avons découvert l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1312191</td>\n",
       "      <td>6852815</td>\n",
       "      <td>2013-08-27</td>\n",
       "      <td>4989227</td>\n",
       "      <td>Sasu</td>\n",
       "      <td>Great house, great people renting it. Highly r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1312191</td>\n",
       "      <td>14022265</td>\n",
       "      <td>2014-06-10</td>\n",
       "      <td>8004355</td>\n",
       "      <td>Rosie</td>\n",
       "      <td>Catrine is very lovely, helpful and stayed in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1312191</td>\n",
       "      <td>82220825</td>\n",
       "      <td>2016-06-26</td>\n",
       "      <td>53892649</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>Nice appartment. Catrine was very helpfull dur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1312191</td>\n",
       "      <td>92695262</td>\n",
       "      <td>2016-08-09</td>\n",
       "      <td>37491893</td>\n",
       "      <td>Julie</td>\n",
       "      <td>7 of us stayed at the home.  We ate most meals...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        id        date  reviewer_id reviewer_name  \\\n",
       "0     1312191   6662965  2013-08-20      7403659          Anne   \n",
       "1     1312191   6852815  2013-08-27      4989227          Sasu   \n",
       "2     1312191  14022265  2014-06-10      8004355         Rosie   \n",
       "3     1312191  82220825  2016-06-26     53892649        Dennis   \n",
       "4     1312191  92695262  2016-08-09     37491893         Julie   \n",
       "\n",
       "                                            comments  \n",
       "0  Nous sommes des français qui avons découvert l...  \n",
       "1  Great house, great people renting it. Highly r...  \n",
       "2  Catrine is very lovely, helpful and stayed in ...  \n",
       "3  Nice appartment. Catrine was very helpfull dur...  \n",
       "4  7 of us stayed at the home.  We ate most meals...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "513d6316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lc/hb2ry3c568xg7y9qdybnfm280000gn/T/ipykernel_75715/3768558691.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'comments': 'Review'}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1312191</td>\n",
       "      <td>6662965</td>\n",
       "      <td>2013-08-20</td>\n",
       "      <td>7403659</td>\n",
       "      <td>Anne</td>\n",
       "      <td>Nous sommes des français qui avons découvert l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1312191</td>\n",
       "      <td>6852815</td>\n",
       "      <td>2013-08-27</td>\n",
       "      <td>4989227</td>\n",
       "      <td>Sasu</td>\n",
       "      <td>Great house, great people renting it. Highly r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1312191</td>\n",
       "      <td>14022265</td>\n",
       "      <td>2014-06-10</td>\n",
       "      <td>8004355</td>\n",
       "      <td>Rosie</td>\n",
       "      <td>Catrine is very lovely, helpful and stayed in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1312191</td>\n",
       "      <td>82220825</td>\n",
       "      <td>2016-06-26</td>\n",
       "      <td>53892649</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>Nice appartment. Catrine was very helpfull dur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1312191</td>\n",
       "      <td>92695262</td>\n",
       "      <td>2016-08-09</td>\n",
       "      <td>37491893</td>\n",
       "      <td>Julie</td>\n",
       "      <td>7 of us stayed at the home.  We ate most meals...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        id        date  reviewer_id reviewer_name  \\\n",
       "0     1312191   6662965  2013-08-20      7403659          Anne   \n",
       "1     1312191   6852815  2013-08-27      4989227          Sasu   \n",
       "2     1312191  14022265  2014-06-10      8004355         Rosie   \n",
       "3     1312191  82220825  2016-06-26     53892649        Dennis   \n",
       "4     1312191  92695262  2016-08-09     37491893         Julie   \n",
       "\n",
       "                                              Review  \n",
       "0  Nous sommes des français qui avons découvert l...  \n",
       "1  Great house, great people renting it. Highly r...  \n",
       "2  Catrine is very lovely, helpful and stayed in ...  \n",
       "3  Nice appartment. Catrine was very helpfull dur...  \n",
       "4  7 of us stayed at the home.  We ate most meals...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Rename the colomns for easier data replacement:\n",
    "df.rename(columns={'comments': 'Review'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb451d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great house, great people renting it. Highly recommended!\n"
     ]
    }
   ],
   "source": [
    "example = df['Review'][1]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb2d4d8",
   "metadata": {},
   "source": [
    "### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38bbf818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Great',\n",
       " 'house',\n",
       " ',',\n",
       " 'great',\n",
       " 'people',\n",
       " 'renting',\n",
       " 'it',\n",
       " '.',\n",
       " 'Highly',\n",
       " 'recommended']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(example)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ad6b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Great', 'NNP'),\n",
       " ('house', 'NN'),\n",
       " (',', ','),\n",
       " ('great', 'JJ'),\n",
       " ('people', 'NNS'),\n",
       " ('renting', 'VBG'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('Highly', 'NNP'),\n",
       " ('recommended', 'VBD')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens) # See meanings here https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "tagged[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a70916",
   "metadata": {},
   "source": [
    "### Dictionary approach (VADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a129ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "878e4491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great house, great people renting it. Highly recommended!\n",
      "{'neg': 0.0, 'neu': 0.321, 'pos': 0.679, 'compound': 0.8906}\n"
     ]
    }
   ],
   "source": [
    "temp = sia.polarity_scores(example)\n",
    "print (example)\n",
    "print (temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3efa1d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ecfdea6e77047068c56c67054aac0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "# Run the polarity score on the entire dataset\n",
    "res = {}\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    text = row['Review']\n",
    "    # if text is float print the index and the text\n",
    "    if isinstance(text, float):\n",
    "        print(row['id'], text)\n",
    "        continue\n",
    "    myid = row['id']\n",
    "    res[myid] = sia.polarity_scores(text)\n",
    "\n",
    "print(len(res))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "169a2e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders = pd.DataFrame(res).T\n",
    "vaders = vaders.reset_index().rename(columns={'index': 'id'})\n",
    "merged = vaders.merge(df, on='id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa7c84",
   "metadata": {},
   "source": [
    "### Pretrained transformer model (Roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "847fe035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8214287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# Because im using my mac m2 where metal is gpu framework (Like cuda for nvidia)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc1477ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great house, great people renting it. Highly recommended!\n",
      "{'neg': 0.0, 'neu': 0.321, 'pos': 0.679, 'compound': 0.8906}\n",
      "{'roberta_neg': 0.002, 'roberta_neu': 0.012, 'roberta_pos': 0.986}\n"
     ]
    }
   ],
   "source": [
    "# VADER results on example for comparison\n",
    "print(example)\n",
    "print(sia.polarity_scores(example))\n",
    "\n",
    "# Roberta\n",
    "# Tokenize and move tensors to the same device as model\n",
    "encoded_text = tokenizer(example, return_tensors=\"pt\")\n",
    "encoded_text = {k: v.to(device) for k, v in encoded_text.items()}\n",
    "\n",
    "# Run inference safely on MPS\n",
    "with torch.no_grad():\n",
    "    output = model(**encoded_text)\n",
    "\n",
    "# Move result to CPU for numpy operations\n",
    "scores = output.logits[0].to(\"cpu\").numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}\n",
    "print({k: round(float(v), 3) for k, v in scores_dict.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b26d02",
   "metadata": {},
   "source": [
    "#### Function to use to do entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c3c9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_scores_roberta(example):\n",
    "    # Tokenize and move to correct device\n",
    "    encoded_text = tokenizer(example, return_tensors=\"pt\")\n",
    "    encoded_text = {k: v.to(device) for k, v in encoded_text.items()}\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_text)\n",
    "\n",
    "    # Move back to CPU for numpy conversion\n",
    "    scores = output.logits[0].to(\"cpu\").numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    # Convert to normal floats\n",
    "    return {\n",
    "        'roberta_neg': float(scores[0]),\n",
    "        'roberta_neu': float(scores[1]),\n",
    "        'roberta_pos': float(scores[2])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f23749f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cacc9d21744cd9b6ea65cdce35e914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 638161805244217263\n",
      "Broke for id 550789736\n",
      "Broke for id 132488805\n",
      "Broke for id 150234786\n",
      "Broke for id 143042997\n",
      "Broke for id 1323121987400475127\n",
      "Broke for id 584507872\n",
      "Broke for id 553102378\n",
      "Broke for id 56143435\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        text = row['Review']\n",
    "        # if text is float print the index and the text\n",
    "        if isinstance(text, float):\n",
    "            print(\"Skipped float value on: \",row['id'], text)\n",
    "            continue\n",
    "        myid = row['id']\n",
    "        \n",
    "        vader_result = sia.polarity_scores(text)\n",
    "        vader_result_rename = {}\n",
    "        for key, value in vader_result.items():\n",
    "            vader_result_rename[f\"vader_{key}\"] = value\n",
    "        roberta_result = polarity_scores_roberta(text)\n",
    "        both = {**vader_result_rename, **roberta_result}\n",
    "        res[myid] = both\n",
    "    except RuntimeError:\n",
    "        print(f'Broke for id {myid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "773d0acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'vader_neg', 'vader_neu', 'vader_pos', 'vader_compound',\n",
       "       'roberta_neg', 'roberta_neu', 'roberta_pos', 'listing_id', 'date',\n",
       "       'reviewer_id', 'reviewer_name', 'Review'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(res).T\n",
    "results_df = results_df.reset_index().rename(columns={'index': 'id'})\n",
    "results_df = results_df.merge(df, how='left')\n",
    "results_df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
